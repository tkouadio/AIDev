# ğŸ¤– PrÃ©diction de lâ€™acceptation des Pull Requests gÃ©nÃ©rÃ©es ou assistÃ©es par lâ€™IA  
**Projet final du cours lâ€™ingÃ©nierie de mise en production des versions logicielles (MGL869) Ã  la maÃ®trise en gÃ©nie logiciel. â€“ AIDev / Mining Software Repositories**

---

## ğŸ“Œ Contexte du projet

Ce projet sâ€™inscrit dans le cadre du projet **AIDev**, proposÃ© Ã  partir du **Mining Challenge MSR** :

- ğŸ”— AIDev: https://github.com/SAILResearch/AI_Teammates_in_SE3  
- ğŸ”— MSR Mining Challenge: https://2026.msrconf.org/track/msr-2026-mining-challenge  
- ğŸ”— Dataset Zenodo: https://zenodo.org/records/16919272  

Lâ€™objectif gÃ©nÃ©ral du projet **AIDev** est dâ€™analyser lâ€™impact des agents dâ€™Intelligence Artificielle (IA) sur la productivitÃ© et la qualitÃ© du dÃ©veloppement logiciel, Ã  partir de donnÃ©es rÃ©elles issues de GitHub.

---

## ğŸ¯ Objectif du projet

Lâ€™objectif spÃ©cifique de ce projet est de rÃ©pondre Ã  la question suivante :

**Peut-on prÃ©dire si une Pull Request gÃ©nÃ©rÃ©e ou assistÃ©e par un agent IA sera acceptÃ©e ou rejetÃ©e ?**

Pour cela, j'ai construit :
- un pipeline complet de donnÃ©es,  
- un modÃ¨le de machine learning interprÃ©table,  
- et une analyse explicative des facteurs influenÃ§ant lâ€™acceptation des Pull Requests.

---

## â“ Questions de recherche (Research Questions)

- **RQ1 :** Quelles caractÃ©ristiques diffÃ©rencient les Pull Requests acceptÃ©es des Pull Requests rejetÃ©es ?  
- **RQ2 :** Est-il possible de prÃ©dire lâ€™acceptation dâ€™une Pull Request IA Ã  partir de ses mÃ©triques ?  
- **RQ3 :** Les agents IA ont-ils un impact significatif sur lâ€™acceptation des Pull Requests, comparativement aux facteurs humains et techniques ?

---

## ğŸ§  Approche et mÃ©thodologie

### ğŸ”¹ 1. Chargement des donnÃ©es

Les donnÃ©es proviennent du dataset officiel **AIDev (Zenodo)**, comprenant :
- Pull Requests  
- Commits et dÃ©tails de commits  
- Reviews et commentaires  
- Informations sur les auteurs  
- Informations sur les dÃ©pÃ´ts  
- Agents IA associÃ©s aux PR  

---

### ğŸ”¹ 2. Feature Engineering

J'ai extrait plusieurs catÃ©gories de mÃ©triques :

**ğŸ“„ Structure de la PR**
- `title_length`, `body_length`

**ğŸ”§ Taille et complexitÃ© du code**
- `commits`, `changed_files`
- `additions`, `deletions`, `total_changes`

**ğŸ‘¥ Collaboration**
- `num_comments`
- `num_reviews`
- `num_review_comments`
- `num_reviewers_unique`

**â± TemporalitÃ©**
- `pr_duration_days`
- `created_hour`

**ğŸ‘¤ Auteur**
- `followers`
- `public_repos`
- `author_tenure_days`

**ğŸ— DÃ©pÃ´t**
- `forks`
- `stars`

**ğŸ¤– Agents IA**
Encodage one-hot :  
- `agent_OpenAI_Codex`, `agent_Copilot`, `agent_Devin`, `agent_Cursor`, `agent_Claude_Code`

---

### ğŸ”¹ 3. ModÃ¨le de Machine Learning

J'ai utilisÃ© un **RandomForestClassifier** pour les raisons suivantes :
- robuste face aux donnÃ©es hÃ©tÃ©rogÃ¨nes,  
- capable de capturer des relations non linÃ©aires,  
- compatible avec **SHAP** pour lâ€™interprÃ©tabilitÃ©.

**ğŸ“Š Split des donnÃ©es :**
- 80 % entraÃ®nement  
- 20 % test  

---

## ğŸ“ˆ RÃ©sultats

### ğŸ¯ Performance du modÃ¨le

- **Accuracy globale :** ~ 88 %  
- **F1-score PR acceptÃ©es :** ~ 0.92  
- **F1-score PR rejetÃ©es :** ~ 0.77  

â¡ï¸ Le modÃ¨le prÃ©dit trÃ¨s bien les PR acceptÃ©es, les PR rejetÃ©es Ã©tant plus difficiles car minoritaires.

---

### ğŸ” InterprÃ©tation avec SHAP

Lâ€™analyse SHAP montre que :

âœ… Les facteurs les plus influents sont :
- durÃ©e de vie de la PR,  
- taille du patch,  
- nombre de reviewers uniques,  
- expÃ©rience de lâ€™auteur.  

âœ… Les agents IA ont un effet rÃ©el mais marginal :
- **OpenAI Codex** a un lÃ©ger effet positif,  
- **Copilot** est globalement neutre,  
- **Devin**, **Cursor** et **Claude Code** ont une influence trÃ¨s faible.  

â¡ï¸ Les agents IA ne sont pas les facteurs dÃ©terminants de lâ€™acceptation.

---

## âš ï¸ Limites du projet

- âŒ Absence dâ€™information sur la prÃ©sence de tests.  
- âŒ Absence de mÃ©triques sur la qualitÃ© sÃ©mantique du code.  
- âŒ Agents IA auto-dÃ©clarÃ©s â†’ bruit possible.  
- âŒ Le modÃ¨le ne capture pas lâ€™intention du mainteneur ni le contexte du projet.

---

## ğŸ“‚ Structure du projet

```

AIDev/
â”œâ”€â”€ data/                     # DonnÃ©es brutes
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ load_data.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ merge_all.py
â”‚   â”œâ”€â”€ train_model.py
â”‚   â””â”€â”€ evaluate_model.py
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ AIDev_Pipeline.ipynb
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ model_rf.joblib
â”‚   â”œâ”€â”€ model_features.csv
â”‚   â”œâ”€â”€ shap_summary_bar.png
â”‚   â”œâ”€â”€ permutation_importances.csv
â”‚   â””â”€â”€ classification_report.txt
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

````

---

## â–¶ï¸ Comment exÃ©cuter le projet

### 1ï¸âƒ£ Installer les dÃ©pendances
```bash
pip install -r requirements.txt
````

### 2ï¸âƒ£ EntraÃ®ner le modÃ¨le

```bash
python scripts/train_model.py
```

### 3ï¸âƒ£ Ã‰valuer le modÃ¨le et gÃ©nÃ©rer les graphiques

```bash
python scripts/evaluate_model.py
```

---

## ğŸ“Œ Conclusion

Ce projet montre quâ€™il est possible de :

* prÃ©dire efficacement lâ€™acceptation des Pull Requests IA,
* comprendre les dÃ©cisions du modÃ¨le grÃ¢ce Ã  SHAP,
* relativiser lâ€™impact des agents IA par rapport aux facteurs humains et techniques.

ğŸ‘‰ Les agents IA influencent les PR, mais ce sont surtout la qualitÃ©, la taille et la collaboration humaine qui dÃ©terminent leur acceptation.

---

## ğŸ‘¤ Auteur

**Thierry Kouadio**
MaÃ®trise en gÃ©nie logiciel â€“ Ã‰TS MontrÃ©al
Projet final â€“ AIDev / Mining Software Repositories

